# Multimodal Stock Prediction Model

A sophisticated machine learning system that combines time series analysis, natural language processing, and employment data to predict stock returns across multiple time horizons with reasonable accuracy.

## ğŸš€ Quick Start

```bash
# Clone and setup
git clone <repository-url>
cd multimodal-stock-modelling
make setup

# Quick training run (recommended)
python train.py --use_mock_data --epochs 10 --optimize_for_mac

# Real data training
python train.py --symbols AAPL MSFT GOOGL --epochs 100 --optimize_for_mac
```

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
- [Training](#training)
- [Performance Optimization](#performance-optimization)
- [Data Sources](#data-sources)
- [Evaluation](#evaluation)
- [API Reference](#api-reference)
- [Contributing](#contributing)

## âœ¨ Features

### Multi-Modal Architecture
- **Time Series**: Temporal Fusion Transformer (TFT) for stock price patterns
- **Text Analysis**: BERT-based sentiment analysis of financial news
- **Employment Data**: Job market indicators and economic signals
- **Cross-Modal Fusion**: Advanced attention mechanisms combining all data sources

### Multi-Horizon Prediction
- **Short-term**: 30-day returns (1-2 months)
- **Medium-term**: 180-day returns (6 months) 
- **Long-term**: 365-day and 730-day returns (1-2 years)
- **Uncertainty Quantification**: Confidence intervals for all predictions

### Advanced Training
- **Multi-task Learning**: Simultaneous return, volatility, and direction prediction
- **Financial Metrics**: Sharpe ratio, Information Coefficient, portfolio performance
- **Mixed Precision**: Faster training with maintained accuracy
- **MacBook Optimization**: Multi-threading optimized for Apple Silicon

## ğŸ›  Installation

### Prerequisites
- Python 3.8+
- macOS (optimized) or Linux
- 8GB+ RAM recommended
- GPU/Apple Silicon recommended

### Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Or use the Makefile
make setup
```

### Dependencies
- PyTorch 2.0+
- Transformers (Hugging Face)
- yfinance, feedparser
- scikit-learn, pandas, numpy
- tensorboard

## ğŸ“Š Usage

### Basic Training

```bash
# Quick test with mock data
python train.py --use_mock_data --epochs 5 --batch_size 32

# Train on real financial data
python train.py --symbols AAPL MSFT GOOGL TSLA --epochs 100
```

### Advanced Training

```bash
# Full configuration example
python train.py \
    --symbols AAPL MSFT GOOGL AMZN TSLA \
    --start_date 2020-01-01 \
    --epochs 200 \
    --batch_size 64 \
    --learning_rate 1e-4 \
    --d_model 512 \
    --n_heads 8 \
    --fusion_strategy cross_attention \
    --optimize_for_mac \
    --mixed_precision \
    --experiment_name production_model
```

### MacBook Optimization

```bash
# Automatic optimization (recommended)
python train.py --optimize_for_mac

# Manual optimization
python train.py --num_workers 4 --pin_memory --persistent_workers
```

### Model Evaluation

```bash
# Evaluate existing model
python train.py --eval_only --resume checkpoints/best_model.pth

# Save predictions
python train.py --eval_only --save_predictions --resume checkpoints/best_model.pth
```

## ğŸ— Model Architecture

### Core Components

1. **Stock Encoder**: TFT-based time series analysis
   - Technical indicators (RSI, MACD, Bollinger Bands)
   - Price and volume patterns
   - Variable selection and attention

2. **News Encoder**: BERT-based text analysis
   - Financial news sentiment
   - Entity recognition
   - Temporal aggregation

3. **Employment Encoder**: Economic indicators
   - Job postings and layoffs
   - Hiring velocity
   - Sector-specific employment

4. **Fusion Layer**: Multi-modal integration
   - Cross-attention mechanisms
   - Gated fusion
   - Hierarchical fusion

5. **Prediction Heads**: Multi-task outputs
   - Return prediction (regression)
   - Direction classification
   - Volatility estimation

### Configuration

```python
config = ModelConfig(
    d_model=256,           # Model dimension
    n_heads=8,             # Attention heads
    sequence_length=252,   # Input length (trading days)
    prediction_horizons=[30, 180, 365, 730],
    fusion_strategy='cross_attention'
)
```

## ğŸ¯ Training

### Training Configuration

```python
training_config = TrainingConfig(
    num_epochs=100,
    batch_size=32,
    learning_rate=1e-4,
    optimizer='adamw',
    scheduler='cosine',
    mixed_precision=True
)
```

### Loss Functions

- **Return Prediction**: MSE, MAE, Huber loss
- **Direction Classification**: Cross-entropy with class weights
- **Volatility Prediction**: Positive-constrained MSE
- **Multi-task Weighting**: Uncertainty-based adaptive weighting

### Metrics

- **Regression**: MSE, MAE, RÂ², Information Coefficient
- **Classification**: Accuracy, Precision, Recall, F1
- **Financial**: Sharpe ratio, Maximum Drawdown, Portfolio returns

## âš¡ Performance Optimization

### MacBook Optimization

The `--optimize_for_mac` flag automatically configures:

- **Threading**: Optimal CPU core utilization
- **Data Loading**: Parallel workers with memory pinning
- **Libraries**: Accelerated BLAS/LAPACK operations

```bash
# Apple Silicon (M1/M2/M3/M4)
python train.py --optimize_for_mac
# Sets: 14 threads, 4 workers, MPS acceleration

# Intel Mac  
python train.py --optimize_for_mac
# Sets: 8 threads, 3 workers, optimized threading
```

### Performance Monitoring

```bash
# Compare optimization impact
python benchmark_performance.py

# Monitor training
tensorboard --logdir runs/
```

## ğŸ“ˆ Data Sources

### Stock Data (yfinance)
- OHLCV prices
- Technical indicators
- Volume patterns
- Dividend adjustments

### News Data (RSS feeds)
- Financial news articles
- Sentiment analysis
- Entity extraction
- Temporal alignment

### Employment Data (Mock/API)
- Job postings by company
- Layoff announcements
- Hiring velocity
- Sector employment trends

### Data Pipeline

```python
# Build unified dataset
builder = UnifiedDatasetBuilder(sequence_length=252)
dataset = builder.build_complete_dataset(
    symbols=['AAPL', 'MSFT'],
    start_date='2020-01-01',
    include_news=True,
    include_employment=True
)
```

## ğŸ“Š Evaluation

### Verification Scripts

```bash
# Test all components
python verify_data_preprocessing.py
python verify_fusion_layer.py  
python verify_training.py

# Performance benchmark
python benchmark_performance.py
```

### Expected Performance

- **Information Coefficient**: 0.05-0.15 (industry standard)
- **Direction Accuracy**: 52-58% (better than random)
- **Sharpe Ratio**: 1.2-2.0 (risk-adjusted returns)
- **Training Speed**: 15-30% faster with optimization

## ğŸ”§ API Reference

### Training Script

```bash
python train.py [OPTIONS]

Model Configuration:
  --d_model INT         Model dimension (default: 256)
  --n_heads INT         Attention heads (default: 8)
  --sequence_length INT Input sequence length (default: 252)
  --fusion_strategy STR Fusion method (cross_attention|gated_fusion|hierarchical|adaptive)

Training Configuration:
  --epochs INT          Training epochs (default: 100)
  --batch_size INT      Batch size (default: 32)
  --learning_rate FLOAT Learning rate (default: 1e-4)
  --optimizer STR       Optimizer (adam|adamw|sgd)
  --scheduler STR       LR scheduler (cosine|step|plateau|none)

Data Configuration:
  --symbols LIST        Stock symbols (default: AAPL MSFT GOOGL)
  --start_date DATE     Start date (default: 2020-01-01)
  --end_date DATE       End date (default: current)
  --use_mock_data       Use synthetic data for testing

Optimization:
  --optimize_for_mac    Auto-optimize for MacBook hardware
  --num_workers INT     Data loading workers
  --pin_memory          Pin memory for faster transfer
  --persistent_workers  Keep workers alive between epochs
  --mixed_precision     Use mixed precision training

Experiment:
  --experiment_name STR Experiment identifier
  --checkpoint_dir STR  Checkpoint directory
  --resume PATH         Resume from checkpoint
  --eval_only           Evaluation only
  --save_predictions    Save test predictions
```

### Python API

```python
from main import MultiModalStockModel, ModelConfig
from training import Trainer, TrainingConfig
from data import UnifiedDatasetBuilder

# Initialize model
config = ModelConfig(d_model=256, n_heads=8)
model = MultiModalStockModel(config)

# Setup training
trainer = Trainer(model, TrainingConfig())
trainer.train(train_loader, val_loader)

# Generate predictions
predictions = trainer.predict(test_loader)
```

## ğŸ§ª Testing

### Run All Tests

```bash
# Data preprocessing verification
python verify_data_preprocessing.py

# Model component verification  
python verify_fusion_layer.py

# Training pipeline verification
python verify_training.py

# Performance benchmark
python benchmark_performance.py
```

### Test Coverage

- âœ… Data loading and preprocessing (6/6 tests)
- âœ… Model architecture and fusion (6/6 tests)  
- âœ… Training pipeline (7/7 tests)
- âœ… Multi-threading optimization
- âœ… Checkpointing and resumption

## ğŸ“ Project Structure

```
multimodal-stock-modelling/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ OPTIMIZATION_GUIDE.md        # MacBook optimization guide
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ Makefile                    # Build automation
â”œâ”€â”€ main.py                     # Core model architecture
â”œâ”€â”€ train.py                    # Training script
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ stock_data.py           # Stock data loading
â”‚   â”œâ”€â”€ news_data.py            # News processing
â”‚   â”œâ”€â”€ employment_data.py      # Employment data
â”‚   â””â”€â”€ unified_dataset.py      # Multi-modal dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ tft_encoder.py          # Time series encoder
â”‚   â”œâ”€â”€ text_encoder.py         # News encoder
â”‚   â”œâ”€â”€ fusion_layer.py         # Multi-modal fusion
â”‚   â””â”€â”€ prediction_heads.py     # Output layers
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ trainer.py              # Training framework
â”‚   â”œâ”€â”€ loss_functions.py       # Multi-task losses
â”‚   â””â”€â”€ metrics.py              # Financial metrics
â”œâ”€â”€ verification/
â”‚   â”œâ”€â”€ verify_data_preprocessing.py
â”‚   â”œâ”€â”€ verify_fusion_layer.py
â”‚   â”œâ”€â”€ verify_training.py
â”‚   â””â”€â”€ benchmark_performance.py
â””â”€â”€ checkpoints/                # Model checkpoints
```

## ğŸ¤ Contributing

### Development Setup

```bash
# Clone repository
git clone <repository-url>
cd multimodal-stock-modelling

# Setup development environment
make setup
make verify

# Run tests before committing
python verify_training.py
```

### Code Style

- Use type hints
- Follow PEP 8
- Add docstrings
- Include tests for new features

### Submitting Changes

1. Create feature branch
2. Add tests
3. Update documentation
4. Submit pull request

## ğŸ“š References

### Academic Papers
- "Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting"
- "Attention Is All You Need" (Transformer architecture)
- "Multi-Task Learning Using Uncertainty Weighting"

### Financial ML
- "Advances in Financial Machine Learning" by Marcos LÃ³pez de Prado
- "Machine Learning for Asset Managers" by Marcos LÃ³pez de Prado

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ”— Links

- **Documentation**: [OPTIMIZATION_GUIDE.md](OPTIMIZATION_GUIDE.md)
- **Issues**: Report bugs and feature requests
- **Discussions**: Community support and questions

---

**Last Updated**: December 2024
**Version**: 1.0.0
**Compatibility**: Python 3.8+, PyTorch 2.0+, macOS/Linux